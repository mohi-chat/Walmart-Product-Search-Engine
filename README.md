# Walmart-Product-Search-Engine

### Project Demo video: https://www.youtube.com/watch?v=t9r7HDujc7g
#### A search engine to look up products listed in Walmart.com. Developed as part of TAMU Datathon 2020. This project secured 2nd Place.

Inspired by the search engine challenge and wanting to try our hand at a real-world dataset we took on the Walmart Datathon challenge. We had the following tasks at hand: 

<b>Task I -:</b> We had to crawl various product information from walmart website to build our product database. This was one of the most laborious and frustrating tasks as we faced a lot of forbidden issues and captcha but this was a great learning step for us as we came across a lot of workarounds and things that we can face while scrapping data and processing it. We used a selenium based crawler with a headless server (phantomjs) for crawling. BeautifulSoup library was used to post process the raw html response. We used a random surfer model to hop from product to product to build up our product database. The final data we crawled can be found here: https://github.com/mohi-chat/Walmart-Product-Search-Engine/blob/main/FlaskApp/search-app/combined.csv

<b>Task II -:</b> To build a preliminary search tool. We started by trying different searching models such as boolean retrieval and used different ranking methods such as vector space model, BM25, TF-IDF scores, etc. We finally ended up using BM25 for ranking and boolean retrieval for matching relevant products. The reason we chose Boolean Retrieval is that the data we are working on is an eCommerce data and while searching for products we usually want exact term matches that we have in our query and Boolean Retrieval does exactly that for us and in a quick manner.

<b>Task III -:</b> To perform clustering on product data, that could aid/enhance the search model developed in task 2. Initially we tried with meanshift clustering, but we didn't get good results with meanshift clustering algorithm. We tried OPTICS as well. In the end, we felt hierarchical clustering would make sense because of the structure of the data. We implemented Agglomerative hierarchical clustering using manhattan distance as the metric, with a distance threshold as 20. Clustering was done on Word2Vec Embeddings with 100-word dimensions. Given a product search query, we could find the cluster of products that matches the most with the query.

<b>Task IV -:</b> To put together a final search engine and expose a UI for everyone to use. Finally we developed a web page using flask API, we created a simple UI due to lack of time. We ended up using an ensemble of our BM25 search model with clustering method to return best search results. The results of search query from BM25 model was first evaluated using cosine similarity scores between the search results and the query and if the best result was below a threshold (after some experimentation we set that to 0.35), then we used the clustering based search. Specially those queries which were not an exact match of product descriptions in the database, clustering based technique performed better than BM25. 
